# Parallel Bellman-Ford Algorithm

## Overview

This project represents my successful implementation of the Parallel Bellman-Ford algorithm, designed to compute the shortest paths from a single source vertex to all other vertices in a weighted directed graph. The primary aim was to familiarize myself with writing sequential code and utilizing parallelism to enhance the algorithm's performance. To achieve this, I employed the ForkJoin framework.

The Bellman-Ford algorithm is a crucial tool for finding shortest paths in graphs, especially when dealing with negative-weight edges and identifying negative cost cycles. One practical application of this algorithm is currency arbitrage detection, which involves spotting sequences of imbalanced currency exchange rates to potentially profit from trading activities. The algorithm repeats these exchanges until a profit is realized.

## Sequential Bellman-Ford Pseudocode

Before delving into the parallel implementation, let's briefly review the sequential Bellman-Ford algorithm's pseudocode:

```java
// Initialization
for each vertex v
    dist[v] = GraphUtil.INF
    pred[v] = -1
dist[source] = 0

// Main algorithm
for n times do
    for each vertex v
        dist_copy[v] = dist[v]
    for each edge (v,w)
        if (dist_copy[v] + cost(v,w)) < dist[w]
            // Found a shorter path to w
            dist[w] = dist_copy[v] + cost(v,w)
            pred[w] = v
```

In this pseudocode:
- `n` represents the number of vertices in the graph.
- `dist` and `dist_copy` are arrays that keep track of computed distances.
- `cost(v,w)` signifies the weight of edge `(v,w)`.
- `pred` is an array used to maintain predecessors.

## Project Achievements

In this project, I successfully implemented various components, including `Parser`, `OutSequential`, `OutParallelBad`, `OutParallelLock`, `InParallel`, `ArrayCopyTask`, `RelaxOutTaskBad`, `RelaxOutTaskLock`, and `RelaxInTask`. These components played pivotal roles in introducing parallelism and optimizing the computation of the Bellman-Ford algorithm.

## Project Restrictions

To challenge myself and hone my skills, I adhered to specific project restrictions:
- Utilized Java's built-in data structure classes from `java.util.*`.
- Avoided importing `java.util.Arrays`, which encouraged me to explore parallelism using my own methods.
- Emphasized designing a well-architected codebase, which contributed significantly to my project's success.

## Graph Generation

This project relied on graphs generated by `GraphUtil.generate()`, which represented graphs as adjacency matrices, complete with edge costs. The generator allowed me to control crucial factors, such as the number of vertices, probabilities of forward and backward edges, and cost ranges for edges.

## Sample Settings

For testing and validation, I experimented with various graph generation settings. Here are some noteworthy examples:

- **N=5:** `(0.5, 2, 4), (0.5, -4, -2)` - Typically resulted in a cycle of length 2 or 3.
- **N=10:** `(0.5, 2, 4), (0.5, -4, -2)` - Usually yielded a cycle of length 3 to 8.
- **N=20:** `(0.2, 3, 10), (0.5, -4, -2)` - Generally led to a cycle of length 6 to 10.
- **N=50:** `(0.1, 5, 30), (0.2, -6, -3)` - Often produced a cycle of length 8 to 16.
- **N=50:** `(0.1, 70, 100), (0.2, -6, -3)` - Resulted in a cycle about half of the time.
- **N=100:** `(0.1, 10, 100), (0.1, -10, -1)` - Typically generated a cycle of length 10 to 20.

## Conclusion

This project has been an exciting journey in exploring the Parallel Bellman-Ford algorithm and the ForkJoin framework. By successfully implementing and optimizing this algorithm, I've not only gained valuable experience in parallel computing but also developed a well-structured codebase that adheres to industry standards.

This README showcases my commitment to writing clean and concise documentation, which is essential for effective communication in software development. I believe this project demonstrates my technical skills and my ability to tackle complex problems. I look forward to discussing this project in more detail during any potential interviews and showcasing the depth of my knowledge and experience in parallel computing and algorithm optimization.
